{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using pretrained, well-known models\n",
    "This notebook aims to create a set of benchmarks for the project, using well-known, thoroughly studied models.\n",
    "Either with pretrained weights, or training with new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "### 21.08.19\n",
    "Attempting to classify with VGG has not proven effective yet.\n",
    "Initially, the image data was note scaled at all. Implemented scaling in the\n",
    "import function, using min-max scaling of the value. This preserves the inherent\n",
    "intensity difference between images.\n",
    "\n",
    "The number of layers of VGG16 used is varied between 3 to 9 without noticable\n",
    "difference. Attempting to find out why, by analyzing the extracted features.\n",
    "The idea is that in order to classify, the feature distribution should be\n",
    "different for images containing single and double events.\n",
    "I first attempt this with manual qualitative inspection.\n",
    "\n",
    "Manual, qualitative inspection reveals that the distributions look very similar.\n",
    "Performing a quantitative study using Kolmogorov-Smirnov two-sample test,\n",
    "comparing the distribution for each feature.\n",
    "\n",
    "* For 1 block (depth 3), the pvalue returned from comparisons is 1.0 for all features.\n",
    "* For 2 blocks (depth 6), the pvalue returned from comparisons is 1.0 for all features.\n",
    "* For 3 blocks (depth 10), the pvalue returned from comparisons is 1.0 for all features.\n",
    "* For 4 blocks, (depth 14) the pvalue returned from comparisons is 1.0 for all features.\n",
    "* For 5 blocks, (depth 18) the pvalue returned from comparisons is 1.0 for all features.\n",
    "\n",
    "This indicates that extracting features using vgg16 doesn't work for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 2\n",
      "Energies shape: (10000, 2)\n",
      "Positions shape: (10000, 4)\n",
      "Labels shape: (10000, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import master_data_functions.functions as dfunc\n",
    "\n",
    "# silence deprecation warnings from tensorflow\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "# File import\n",
    "# Sample filenames are:\n",
    "# CeBr10kSingle_1.txt -> single events, \n",
    "# CeBr10kSingle_2.txt -> single events\n",
    "# CeBr10k_1.txt -> mixed single and double events \n",
    "# CeBr10.txt -> small file of 10 samples\n",
    "\n",
    "keywords = {\n",
    "    \"single_1\": \"CeBr10kSingle_1\",\n",
    "    \"single_2\": \"CeBr10kSingle_2\",\n",
    "    \"mix\": \"CeBr10k_1\",\n",
    "    \"small\": \"CeBr10\"}\n",
    "    \n",
    "dataset = \"mix\"\n",
    "data = dfunc.import_data(\"sample\")\n",
    "images = data[keywords[dataset]][\"images\"]\n",
    "energies = data[keywords[dataset]][\"energies\"]\n",
    "positions = data[keywords[dataset]][\"positions\"]\n",
    "labels = to_categorical(data[keywords[dataset]][\"labels\"])\n",
    "n_classes = labels.shape[1]\n",
    "\n",
    "\n",
    "print(\"Number of classes: {}\".format(n_classes))\n",
    "print(\"Energies shape: {}\".format(energies.shape))\n",
    "print(\"Positions shape: {}\".format(positions.shape))\n",
    "print(\"Labels shape: {}\".format(labels.shape))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image data shape: (10000, 16, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "# VGG16 expects 3 channels. Solving this by concatenating the image data \n",
    "# to itself, to form three identical channels\n",
    "\n",
    "images = np.concatenate((images, images, images), axis=3)\n",
    "\n",
    "print(\"Image data shape: {}\".format(images.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-16 feature extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        multiple                  1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        multiple                  36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        multiple                  73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        multiple                  147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        multiple                  295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        multiple                  590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        multiple                  590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        multiple                  1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from master_models.pretrained import vgg_model\n",
    "vgg = vgg_model(output_depth=18)\n",
    "vgg.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features with vgg\n",
    "vgg_features = vgg.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check distribution of features\n",
    "\n",
    "manual_inspect = False\n",
    "\n",
    "single_features = vgg_features[np.where(labels[:,0] == 1)]\n",
    "double_features = vgg_features[np.where(labels[:,1] == 1)]\n",
    "\n",
    "if manual_inspect:\n",
    "    index = 9 \n",
    "    fig, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(12,12))\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            # plot features\n",
    "            ax[i, j].hist(single_features[:,index + i*3 + j], alpha=0.5, label='single')\n",
    "            ax[i, j].hist(double_features[:,index + i*3 + j], alpha=0.5, label='double')\n",
    "            ax[i, j].legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 512 out of 512 | elapsed:    8.8s finished\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "# Check difference using Kolmogorov-Smirnov\n",
    "\n",
    "def get_pval(i):\n",
    "    ks = ks_2samp(single_features[:,i], double_features[:,i])\n",
    "    return ks.pvalue\n",
    "\n",
    "n = vgg_features.shape[1]\n",
    "p_values = Parallel(n_jobs=-1, verbose=2)(delayed(get_pval)(i) for i in range(n))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(p_values)), p_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with custom dense network\n",
    "### Build dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a fully-connected network to classify based on\n",
    "# extracted features\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "model = Sequential()\n",
    "model.add(Dense(4096, input_shape=vgg_features.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(vgg_features, labels, test_size = 0.2)\n",
    "print(\"Training and test data shapes:\")\n",
    "print(\"x_train: {}\".format(x_train.shape))\n",
    "print(\"x_test: {}\".format(x_test.shape))\n",
    "print(\"y_train: {}\".format(y_train.shape))\n",
    "print(\"y_test: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=10, \n",
    "    batch_size=128,\n",
    "    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check predictions\n",
    "predicted = model.predict(x_test)\n",
    "print(len(predicted[np.where(predicted[:,1] == 1.0)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pretrained_venv",
   "language": "python",
   "name": "pretrained_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
