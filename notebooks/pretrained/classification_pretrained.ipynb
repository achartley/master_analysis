{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using pretrained, well-known models\n",
    "This notebook aims to create a set of benchmarks for the project, using well-known, thoroughly studied models.\n",
    "Either with pretrained weights, or training with new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "### 21.08.19\n",
    "Attempting to classify with VGG has not proven effective yet.\n",
    "Initially, the image data was note scaled at all. Implemented scaling in the\n",
    "import function, using min-max scaling of the value. This preserves the inherent\n",
    "intensity difference between images.\n",
    "\n",
    "The number of layers of VGG16 used is varied between 3 to 9 without noticable\n",
    "difference. Attempting to find out why, by analyzing the extracted features.\n",
    "The idea is that in order to classify, the feature distribution should be\n",
    "different for images containing single and double events.\n",
    "I first attempt this with manual qualitative inspection.\n",
    "\n",
    "Manual, qualitative inspection reveals that the distributions look very similar.\n",
    "Performing a quantitative study using Kolmogorov-Smirnov two-sample test,\n",
    "comparing the distribution for each feature.\n",
    "\n",
    "* For 1 block (depth 3), the pvalue returned from comparisons is 1.0 for all features.\n",
    "* For 2 blocks (depth 6), the pvalue returned from comparisons is 1.0 for all features.\n",
    "* For 3 blocks (depth 10), the pvalue returned from comparisons is 1.0 for all features.\n",
    "* For 4 blocks, (depth 14) the pvalue returned from comparisons is 1.0 for all features.\n",
    "* For 5 blocks, (depth 18) the pvalue returned from comparisons is 1.0 for all features.\n",
    "\n",
    "This indicates that extracting features using vgg16 doesn't work for classification.\n",
    "I still want to confirm that the weights of the vgg layers are the imagenet weights.\n",
    "\n",
    "### 22.08.19\n",
    "Going to use a reference image from imagenet to verify that the vgg-layers behave\n",
    "as expected.\n",
    "* Reference produces very similar feature output as simulated data\n",
    "\n",
    "Rewrote the vgg_model script to be able to import any pretrained model from\n",
    "tensorflow, and extended data import to handle single files (for large file)\n",
    "and possibility to specify number of samples to include.\n",
    "\n",
    "### 23.08.19\n",
    "Import scripts fixed so that array dimensions are correct independent of folder or single\n",
    "file import.\n",
    "\n",
    "Tests on multiple nets with 10k events give same results as for VGG.\n",
    "\n",
    "### 24.08.19\n",
    "Running checks on feature distribution with the full networks and 200k events.\n",
    "With 200k events there are models which from the p-value given by the KS two-sample test\n",
    "should be possible to classify with. Interstingly, VGG16 and VGG19 show a large variance in which\n",
    "features are seemingly drawn from different distributions.\n",
    "\n",
    "Need to run for: NASNetLarge, ResNet50 and Xception, but running into memory problems.\n",
    "\n",
    "### 25.08.19\n",
    "Some NaN values in output features from VGG. When removed, the network trains to acc = 0.9\n",
    "on the features. \n",
    "\n",
    "Implemented save_feature_representation and load_feature_representation.\n",
    "\n",
    "### 04.09.19\n",
    "Storing 200k events to use for generating feature representations for classification.\n",
    "\n",
    "### 09.09.19\n",
    "Previously trained fully connected nets on the feature output from all pretrained networks available\n",
    "at full depth. The fully-connected nets were configured so that the input layer had a number of nodes\n",
    "equal to the number of features output from the convolutional block before it (because the input shape\n",
    "must be defined). After that, two layers of 512 nodes with RELu actication functions, into one\n",
    "2-node layer with softmax.\n",
    "Results:\n",
    "* __DenseNet121__: \n",
    "    Accuracy starts around 0.86 first epoch and rises to just under 0.94 at maximum.\n",
    "    Somewhat unstable.\n",
    "* __DenseNet169__: \n",
    "    Very similar to DenseNet121, but starts at around 0.90\n",
    "* __DenseNet201__: \n",
    "    Very similar to other two DenseNets, but more stable above 0.92 for epoch 4+.\n",
    "* __InceptionResNetV2__: \n",
    "    Starts at 0.84, maxes just above 0.88. A bit zig-zag.\n",
    "* __InceptionV3__: \n",
    "    Similar to V2 above, but starts lower and maxes out higher (0.90). Huge dip at epoch 7,\n",
    "    around same spot as DenseNets.\n",
    "* __MobileNet__: \n",
    "    Didn't learn anything.\n",
    "* __MobileNetV2__: \n",
    "    Didn't learn anything.\n",
    "* __NASNetLarge__: \n",
    "    Starts at 0.88, maxes out at 0.92 ish. Stable nice increase in accuracy with small dip at last epoch.\n",
    "* __NASNetMobile__: \n",
    "    Roughly same as NASNetLarge, but a little more zig-zag in the curve.\n",
    "* __ResNet50__: \n",
    "    Didn't learn anything.\n",
    "* __VGG16__: \n",
    "    A lot of zig-zag, but between 0.88 and just under 0.92 (max), so it's a small span.\n",
    "    Stops zig-zagging on max and becomes pretty much flat.\n",
    "* __VGG19__: \n",
    "    Smaller zig-zag distances, steady increase up to around 0.90 for maximum.\n",
    "* __Xception__: \n",
    "    Starts high (0.88) and slowly rises to a maximum of 0.92, a dip around epoch 6 like many others.\n",
    "    \n",
    "From this I think the nets that didn't weren't able to extract anything from the features can be\n",
    "ignored for a while, to focus on those that performed well. This leaves the following nets as possible\n",
    "points of interest:\n",
    "* DenseNet201 (best of the DenseNets, keep the others in mind)\n",
    "* NASNetLarge (keep NASNetMobile in mind)\n",
    "* VGG16\n",
    "* VGG19\n",
    "* Xception\n",
    "\n",
    "### 15.09.19\n",
    "Simple implementation of distance-checking of double events done.\n",
    "Results indicate that the model struggles more with events that are close together.\n",
    "Specifically, I've looked at the ratio of correctly classified double events where\n",
    "the events are less than 3mm apart.\n",
    "\n",
    "### 16.09.19\n",
    "* Compare feature distributions of single events and double events with distance < 3mm.\n",
    "Plots produced. There is a similar difference between single events and close double events,\n",
    "as between single events and double events in general.\n",
    "\n",
    "* Is the number of close events large enough to be confident in the result of the KS two-sample test?\n",
    "* What does the above result imply?\n",
    "* Is weighting the training data such that close events are weighted higher than others a good idea? Would this introduce a bias?\n",
    "\n",
    "### 18.09.19\n",
    "Producing histograms of correct vs wrong classifications for predictions on double events, specifically.\n",
    "This gives additional insight in how well the models classify events, especially compared with the total\n",
    "accuracy. An example is VGG16: The total accuracy for classification is around 0.88-0.92, but when looking\n",
    "at event with a distance lower than 3mm between them, the ratio of correctly classified close events is \n",
    "around 0.4. Densenet201 full depth has comparable total accuracy, but a ratio for close events at 0.72, \n",
    "which is significantly better.\n",
    "\n",
    "### 23.09.19\n",
    "Distance calculations have been corrected. Relative energy implemented.\n",
    "MobileNet and ResNet50 aren't able to learn anything, so they will be excluded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Implement functions to save and load trained fully-connected networks\n",
    "* Need a way to compare models where validation and test data is consistent.\n",
    "    * This can be part of a new train_test_split which also creates validation data. Could possibly be solved by simply doing train_test_split twice. first on full data, then on the resulting test-data.\n",
    "* Implement realtive energy comparison with histogram plots to compare similarly to distances.\n",
    "* Produce comparison plots for the most successful pretrained models, with all numbers output as table.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from master_data_functions.functions import import_data,save_feature_representation,load_feature_representation\n",
    "from master_models.pretrained import pretrained_model\n",
    "from master_data_functions.functions import event_indices, relative_distance, relative_energy\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 2\n",
      "Images shape: (200000, 16, 16, 1)\n",
      "Energies shape: (200000, 2)\n",
      "Positions shape: (200000, 4)\n",
      "Labels shape: (200000, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# File import\n",
    "# Sample filenames are:\n",
    "# CeBr10kSingle_1.txt -> single events, \n",
    "# CeBr10kSingle_2.txt -> single events\n",
    "# CeBr10k_1.txt -> mixed single and double events \n",
    "# CeBr10.txt -> small file of 10 samples\n",
    "# CeBr2Mil_Mix.txt -> 2 million mixed samples of simulated events\n",
    "\n",
    "# Flag import, since we can now import 200k events from .npy files\n",
    "from_file = False\n",
    "if from_file:\n",
    "\n",
    "    folder = \"simulated\"\n",
    "    filename = \"CeBr2Mil_Mix.txt\"\n",
    "    num_samples = 2e5\n",
    "    #folder = \"sample\"\n",
    "    #filename = \"CeBr10k_1.txt\"\n",
    "    #num_samples = 1e3\n",
    "\n",
    "    data = import_data(folder=folder, filename=filename, num_samples=num_samples)\n",
    "    images = data[filename][\"images\"]\n",
    "    energies = data[filename][\"energies\"]\n",
    "    positions = data[filename][\"positions\"]\n",
    "    labels = to_categorical(data[filename][\"labels\"])\n",
    "    n_classes = labels.shape[1]\n",
    "else:\n",
    "    images = load_feature_representation(\"images_200k.npy\")\n",
    "    energies = load_feature_representation(\"energies_200k.npy\")\n",
    "    positions = load_feature_representation(\"positions_200k.npy\")\n",
    "    labels = load_feature_representation(\"labels_200k.npy\")\n",
    "\n",
    "n_classes = labels.shape[1]\n",
    "print(\"Number of classes: {}\".format(n_classes))\n",
    "print(\"Images shape: {}\".format(images.shape))\n",
    "print(\"Energies shape: {}\".format(energies.shape))\n",
    "print(\"Positions shape: {}\".format(positions.shape))\n",
    "print(\"Labels shape: {}\".format(labels.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 expects 3 channels. Solving this by concatenating the image data \n",
    "# to itself, to form three identical channels\n",
    "\n",
    "images = np.concatenate((images, images, images), axis=3)\n",
    "print(\"Image data shape: {}\".format(images.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with custom dense network\n",
    "### Multiple dense model\n",
    "Build a dense model for each pretrained model form which a feature representation has been saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keys: model names, Values: depth to compare at.\n",
    "pretrained_models = {\n",
    "    \"DenseNet121\":None, #8\n",
    "    \"DenseNet169\":None, #8\n",
    "    \"DenseNet201\":None, #8\n",
    "    \"InceptionResNetV2\":None, #8\n",
    "    \"InceptionV3\":None, #8\n",
    "    #\"MobileNet\":None, #8\n",
    "    \"MobileNetV2\":None, #5\n",
    "    \"NASNetLarge\":None, #4\n",
    "    \"NASNetMobile\":None, #4\n",
    "    #\"ResNet50\":None, #8\n",
    "    \"VGG16\":None,\n",
    "    \"VGG19\":None,\n",
    "    \"Xception\":None, #6\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train a fully-connected network to classify based on\n",
    "# extracted features\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "# Set up and train a network for each of the pretrained features available    \n",
    "for net, depth in pretrained_models.items():\n",
    "    print(\"Running for:\", net)\n",
    "    \n",
    "    # Load features\n",
    "    if depth is None:\n",
    "        depth = \"full\"\n",
    "    features_filename = net + \"_d\" + str(depth) + \"_\" + str(images.shape[0]) + \".npy\"\n",
    "    pretrained_features = load_feature_representation(features_filename)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=pretrained_features.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Remove nan values from pretrained_features (and remove labels which produces them)\n",
    "    nan_indices = []\n",
    "    for i in range(pretrained_features.shape[0]):\n",
    "        if np.isnan(pretrained_features[i,:]).any():\n",
    "            nan_indices.append(i)\n",
    "    pretrained_features = np.delete(pretrained_features, nan_indices, axis=0)\n",
    "    tmp_labels = np.delete(labels, nan_indices, axis=0)\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(pretrained_features, tmp_labels, test_size = 0.2)    \n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x_train, \n",
    "        y_train, \n",
    "        epochs=10, \n",
    "        batch_size=32,\n",
    "        validation_data=(x_test, y_test))\n",
    "    \n",
    "    acc_filename = net + \"_d\" + str(depth) + \"_\" + str(pretrained_features.shape[0]) + \"_accuracy\"\n",
    "    loss_filename = net + \"_d\" + str(depth) + \"_\" + str(pretrained_features.shape[0]) + \"_loss\"\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.savefig(acc_filename)\n",
    "    plt.clf()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.savefig(loss_filename)\n",
    "    plt.clf()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single dense model for one pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Single net testing\n",
    "\n",
    "net = \"DenseNet201\"\n",
    "depth = \"full\"\n",
    "epochs = 5\n",
    "# Load features\n",
    "features_filename = net + \"_d\" + str(depth) + \"_\" + str(images.shape[0]) + \".npy\"\n",
    "pretrained_features = load_feature_representation(features_filename)\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=pretrained_features.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Remove nan values from pretrained_features (and remove labels which produces them)\n",
    "nan_indices = []\n",
    "for i in range(pretrained_features.shape[0]):\n",
    "    if np.isnan(pretrained_features[i,:]).any():\n",
    "        nan_indices.append(i)\n",
    "pretrained_features = np.delete(pretrained_features, nan_indices, axis=0)\n",
    "tmp_labels = np.delete(labels, nan_indices, axis=0)\n",
    "tmp_positions = np.delete(positions, nan_indices, axis=0)\n",
    "tmp_energies = np.delete(energies, nan_indices, axis=0)\n",
    "\n",
    "labels_positions_energies = np.concatenate((tmp_labels, tmp_positions, tmp_energies), axis=1)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(pretrained_features, labels_positions_energies, test_size = 0.2)    \n",
    "\n",
    "test_positions = y_test[:, 2:6]\n",
    "train_positions = y_train[:, 2:6]\n",
    "test_energies = y_test[:, 6:]\n",
    "train_energies = y_train[:, 6:]\n",
    "y_test = y_test[:, :2]\n",
    "y_train = y_train[:, :2]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=epochs, \n",
    "    batch_size=32,\n",
    "    validation_split=0.1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on test set and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_predicted = model.predict(x_test)\n",
    "tmp_results = tmp_predicted.argmax(axis=-1).reshape(tmp_predicted.shape[0], 1)\n",
    "\n",
    "# indices, relative distances and relative energies for test set\n",
    "single_indices, double_indices, close_indices = event_indices(test_positions)\n",
    "rel_distance = relative_distance(test_positions)\n",
    "rel_energy = relative_energy(test_energies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_doubles = np.where(tmp_results[double_indices] == 1)[0]\n",
    "print(len(np.where(rel_energy[double_indices] != -100)[0]))\n",
    "print(len(np.where(rel_energy[double_indices][correct_doubles] == -100)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separate correct and wrong classifications\n",
    "\n",
    "\n",
    "correct_doubles = np.where(tmp_results[double_indices] == 1)[0]\n",
    "wrong_doubles = np.where(tmp_results[double_indices] == 0)[0]\n",
    "\n",
    "mean_correct = np.mean(rel_distance[double_indices][correct_doubles])\n",
    "mean_wrong = np.mean(rel_distance[double_indices][wrong_doubles])\n",
    "mean_all = np.mean(rel_distance[double_indices])\n",
    "\n",
    "ratio_doubles = len(correct_doubles) / len(double_indices)\n",
    "\n",
    "# Ratio of correctly classified double events with a distance between\n",
    "# events < 3mm\n",
    "n_close = len(close_indices)\n",
    "n_close_correct = len(np.where(rel_distance[double_indices][correct_doubles] < 3.0)[0])\n",
    "ratio_close = n_close_correct / n_close\n",
    "print(len(correct_doubles))\n",
    "print(len(wrong_doubles))\n",
    "\n",
    "# Output\n",
    "print(\"Mean dist all double events: \", mean_all)\n",
    "print(\"Mean dist correct double events: \", mean_correct)\n",
    "print(\"Mean dist wrong double events: \", mean_wrong)\n",
    "print(\"Ratio of correctly classified double events: \", ratio_doubles)\n",
    "print(\"Ratio correctly classified events with dist < 3mm: \", ratio_close)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histograms\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12,8))\n",
    "ax[0,0].hist(rel_distance[double_indices][correct_doubles], bins=50, alpha=0.5, label=\"correct\")\n",
    "ax[0,0].hist(rel_distance[double_indices][wrong_doubles], bins=50, alpha=0.5, label=\"wrong\")\n",
    "ax[0,0].set_title(\"Relative distance\")\n",
    "ax[0,0].legend()\n",
    "ax[0,1].hist(rel_energy[double_indices][correct_doubles], bins=50, alpha=0.5, label=\"correct\")\n",
    "ax[0,1].hist(rel_energy[double_indices][wrong_doubles], bins=50, alpha=0.5, label=\"wrong\")\n",
    "ax[0,1].set_title(\"Relative energy\")\n",
    "ax[0,1].legend()\n",
    "ax[1,0].hist(rel_distance[double_indices], bins=50)\n",
    "ax[1,0].set_title(\"Distribution of relative distances\")\n",
    "ax[1,1].hist(rel_energy[double_indices], bins=50)\n",
    "ax[1,1].set_title(\"Distribution of relative energies\")\n",
    "#ax[1].text(0, 600, r'  $\\mu$ correct = {:.2f} mm'.format(mean_correct))\n",
    "#ax[1].text(0, 550, r'  $\\mu$ wrong = {:.2f} mm'.format(mean_wrong))\n",
    "#ax[1].text(0, 500, r'  ratio doubles < 3mm = {:.2f}'.format(ratio_doubles))\n",
    "#ax[1].text(0, 650, r'  $\\mu$ all = {:.2f} mm'.format(mean_all))\n",
    "#ax[1].set_title(\"Numbers\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: DenseNet121\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/5\n",
      "144000/144000 [==============================] - 19s 131us/sample - loss: 0.3487 - accuracy: 0.8485 - val_loss: 0.2740 - val_accuracy: 0.8972\n",
      "Epoch 2/5\n",
      "144000/144000 [==============================] - 19s 133us/sample - loss: 0.2815 - accuracy: 0.8888 - val_loss: 0.2281 - val_accuracy: 0.9173\n",
      "Epoch 3/5\n",
      "144000/144000 [==============================] - 19s 133us/sample - loss: 0.2562 - accuracy: 0.9023 - val_loss: 0.2264 - val_accuracy: 0.9172\n",
      "Epoch 4/5\n",
      "144000/144000 [==============================] - 19s 133us/sample - loss: 0.2442 - accuracy: 0.9075 - val_loss: 0.2102 - val_accuracy: 0.9259\n",
      "Epoch 5/5\n",
      "144000/144000 [==============================] - 19s 132us/sample - loss: 0.2349 - accuracy: 0.9122 - val_loss: 0.2168 - val_accuracy: 0.9269\n",
      "Running for: DenseNet169\n",
      "Train on 143998 samples, validate on 16000 samples\n",
      "Epoch 1/5\n",
      "143998/143998 [==============================] - 19s 135us/sample - loss: 0.3256 - accuracy: 0.8633 - val_loss: 0.2998 - val_accuracy: 0.8757\n",
      "Epoch 2/5\n",
      "143998/143998 [==============================] - 19s 134us/sample - loss: 0.2684 - accuracy: 0.8959 - val_loss: 0.2277 - val_accuracy: 0.9161\n",
      "Epoch 3/5\n",
      "143998/143998 [==============================] - 19s 132us/sample - loss: 0.2487 - accuracy: 0.9052 - val_loss: 0.2723 - val_accuracy: 0.8865\n",
      "Epoch 4/5\n",
      "143998/143998 [==============================] - 19s 134us/sample - loss: 0.2348 - accuracy: 0.9125 - val_loss: 0.2298 - val_accuracy: 0.9177\n",
      "Epoch 5/5\n",
      "143998/143998 [==============================] - 19s 134us/sample - loss: 0.2257 - accuracy: 0.9172 - val_loss: 0.3383 - val_accuracy: 0.8572\n",
      "Running for: DenseNet201\n",
      "Train on 143998 samples, validate on 16000 samples\n",
      "Epoch 1/5\n",
      "143998/143998 [==============================] - 19s 132us/sample - loss: 0.3258 - accuracy: 0.8616 - val_loss: 0.2757 - val_accuracy: 0.8882\n",
      "Epoch 2/5\n",
      "143998/143998 [==============================] - 19s 131us/sample - loss: 0.2625 - accuracy: 0.8976 - val_loss: 0.2686 - val_accuracy: 0.8968\n",
      "Epoch 3/5\n",
      "143998/143998 [==============================] - 19s 131us/sample - loss: 0.2316 - accuracy: 0.9139 - val_loss: 0.2508 - val_accuracy: 0.9084\n",
      "Epoch 4/5\n",
      "143998/143998 [==============================] - 19s 131us/sample - loss: 0.2170 - accuracy: 0.9204 - val_loss: 0.2028 - val_accuracy: 0.9309\n",
      "Epoch 5/5\n",
      "143998/143998 [==============================] - 19s 131us/sample - loss: 0.2081 - accuracy: 0.9254 - val_loss: 0.2271 - val_accuracy: 0.9188\n",
      "Running for: InceptionResNetV2\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/5\n",
      "144000/144000 [==============================] - 18s 126us/sample - loss: 0.4740 - accuracy: 0.7674 - val_loss: 0.3762 - val_accuracy: 0.8411\n",
      "Epoch 2/5\n",
      "144000/144000 [==============================] - 18s 127us/sample - loss: 0.3798 - accuracy: 0.8343 - val_loss: 0.3602 - val_accuracy: 0.8518\n",
      "Epoch 3/5\n",
      "144000/144000 [==============================] - 18s 127us/sample - loss: 0.3481 - accuracy: 0.8536 - val_loss: 0.3185 - val_accuracy: 0.8712\n",
      "Epoch 4/5\n",
      "144000/144000 [==============================] - 18s 126us/sample - loss: 0.3310 - accuracy: 0.8632 - val_loss: 0.3124 - val_accuracy: 0.8754\n",
      "Epoch 5/5\n",
      "144000/144000 [==============================] - 18s 126us/sample - loss: 0.3196 - accuracy: 0.8700 - val_loss: 0.3121 - val_accuracy: 0.8744\n",
      "Running for: InceptionV3\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/5\n",
      "144000/144000 [==============================] - 18s 128us/sample - loss: 0.4787 - accuracy: 0.7609 - val_loss: 0.4110 - val_accuracy: 0.8167\n",
      "Epoch 2/5\n",
      "144000/144000 [==============================] - 18s 128us/sample - loss: 0.3871 - accuracy: 0.8268 - val_loss: 0.3597 - val_accuracy: 0.8439\n",
      "Epoch 3/5\n",
      "144000/144000 [==============================] - 18s 128us/sample - loss: 0.3533 - accuracy: 0.8495 - val_loss: 0.3275 - val_accuracy: 0.8639\n",
      "Epoch 4/5\n",
      "144000/144000 [==============================] - 18s 128us/sample - loss: 0.3312 - accuracy: 0.8617 - val_loss: 0.3015 - val_accuracy: 0.8809\n",
      "Epoch 5/5\n",
      "144000/144000 [==============================] - 18s 128us/sample - loss: 0.3165 - accuracy: 0.8707 - val_loss: 0.3308 - val_accuracy: 0.8593\n",
      "Running for: MobileNet\n",
      "Train on 143998 samples, validate on 16000 samples\n",
      "Epoch 1/5\n",
      "143998/143998 [==============================] - 30s 210us/sample - loss: 7.7012 - accuracy: 0.4991 - val_loss: 7.5704 - val_accuracy: 0.5077\n",
      "Epoch 2/5\n",
      "143998/143998 [==============================] - 30s 210us/sample - loss: 7.7019 - accuracy: 0.4992 - val_loss: 7.5704 - val_accuracy: 0.5077\n",
      "Epoch 3/5\n",
      "143998/143998 [==============================] - 31s 212us/sample - loss: 7.7019 - accuracy: 0.4992 - val_loss: 7.5704 - val_accuracy: 0.5077\n",
      "Epoch 4/5\n",
      "143998/143998 [==============================] - 30s 209us/sample - loss: 7.7019 - accuracy: 0.4992 - val_loss: 7.5704 - val_accuracy: 0.5077\n",
      "Epoch 5/5\n",
      "143998/143998 [==============================] - 30s 209us/sample - loss: 7.7019 - accuracy: 0.4992 - val_loss: 7.5704 - val_accuracy: 0.5077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: MobileNetV2\n",
      "Train on 143998 samples, validate on 16000 samples\n",
      "Epoch 1/5\n",
      "143998/143998 [==============================] - 19s 133us/sample - loss: 0.3020 - accuracy: 0.8822 - val_loss: 0.2290 - val_accuracy: 0.9174\n",
      "Epoch 2/5\n",
      "143998/143998 [==============================] - 19s 132us/sample - loss: 0.2197 - accuracy: 0.9208 - val_loss: 0.2012 - val_accuracy: 0.9283\n",
      "Epoch 3/5\n",
      "143998/143998 [==============================] - 19s 133us/sample - loss: 0.1966 - accuracy: 0.9316 - val_loss: 0.1961 - val_accuracy: 0.9259\n",
      "Epoch 4/5\n",
      "143998/143998 [==============================] - 19s 133us/sample - loss: 0.1856 - accuracy: 0.9363 - val_loss: 0.1945 - val_accuracy: 0.9302\n",
      "Epoch 5/5\n",
      "143998/143998 [==============================] - 19s 131us/sample - loss: 0.1777 - accuracy: 0.9395 - val_loss: 0.1672 - val_accuracy: 0.9438\n",
      "Running for: NASNetLarge\n",
      "Train on 143998 samples, validate on 16000 samples\n",
      "Epoch 1/5\n",
      "143998/143998 [==============================] - 30s 211us/sample - loss: 0.3655 - accuracy: 0.8437 - val_loss: 0.3017 - val_accuracy: 0.8819\n",
      "Epoch 2/5\n",
      "143998/143998 [==============================] - 30s 210us/sample - loss: 0.2825 - accuracy: 0.8915 - val_loss: 0.2648 - val_accuracy: 0.9021\n",
      "Epoch 3/5\n",
      "143998/143998 [==============================] - 30s 210us/sample - loss: 0.2539 - accuracy: 0.9053 - val_loss: 0.2492 - val_accuracy: 0.9062\n",
      "Epoch 4/5\n",
      "143998/143998 [==============================] - 30s 210us/sample - loss: 0.2378 - accuracy: 0.9130 - val_loss: 0.2279 - val_accuracy: 0.9183\n",
      "Epoch 5/5\n",
      "143998/143998 [==============================] - 30s 210us/sample - loss: 0.2261 - accuracy: 0.9177 - val_loss: 0.2189 - val_accuracy: 0.9224\n",
      "Running for: NASNetMobile\n",
      "Train on 143998 samples, validate on 16000 samples\n",
      "Epoch 1/5\n",
      "143998/143998 [==============================] - 20s 140us/sample - loss: 0.3819 - accuracy: 0.8358 - val_loss: 0.3106 - val_accuracy: 0.8761\n",
      "Epoch 2/5\n",
      "143998/143998 [==============================] - 20s 139us/sample - loss: 0.2995 - accuracy: 0.8823 - val_loss: 0.2913 - val_accuracy: 0.8839\n",
      "Epoch 3/5\n",
      "143998/143998 [==============================] - 20s 139us/sample - loss: 0.2673 - accuracy: 0.8990 - val_loss: 0.2440 - val_accuracy: 0.9129\n",
      "Epoch 4/5\n",
      "143998/143998 [==============================] - 20s 140us/sample - loss: 0.2496 - accuracy: 0.9076 - val_loss: 0.2429 - val_accuracy: 0.9093\n",
      "Epoch 5/5\n",
      "143998/143998 [==============================] - 20s 139us/sample - loss: 0.2371 - accuracy: 0.9131 - val_loss: 0.2431 - val_accuracy: 0.9114\n",
      "Running for: ResNet50\n",
      "Train on 143998 samples, validate on 16000 samples\n",
      "Epoch 1/5\n",
      "143998/143998 [==============================] - 48s 332us/sample - loss: 7.6914 - accuracy: 0.4998 - val_loss: 7.7501 - val_accuracy: 0.4961\n",
      "Epoch 2/5\n",
      "143998/143998 [==============================] - 48s 332us/sample - loss: 7.6934 - accuracy: 0.4997 - val_loss: 7.7501 - val_accuracy: 0.4961\n",
      "Epoch 3/5\n",
      "143998/143998 [==============================] - 48s 332us/sample - loss: 7.6934 - accuracy: 0.4997 - val_loss: 7.7501 - val_accuracy: 0.4961\n",
      "Epoch 4/5\n",
      "143998/143998 [==============================] - 48s 331us/sample - loss: 7.6934 - accuracy: 0.4997 - val_loss: 7.7501 - val_accuracy: 0.4961\n",
      "Epoch 5/5\n",
      "143998/143998 [==============================] - 48s 332us/sample - loss: 7.6934 - accuracy: 0.4997 - val_loss: 7.7501 - val_accuracy: 0.4961\n",
      "Running for: VGG16\n",
      "Train on 143998 samples, validate on 16000 samples\n",
      "Epoch 1/5\n",
      "143998/143998 [==============================] - 19s 132us/sample - loss: 0.3094 - accuracy: 0.8751 - val_loss: 0.3836 - val_accuracy: 0.8514\n",
      "Epoch 2/5\n",
      "143998/143998 [==============================] - 19s 131us/sample - loss: 0.2704 - accuracy: 0.8969 - val_loss: 0.2734 - val_accuracy: 0.8946\n",
      "Epoch 3/5\n",
      "143998/143998 [==============================] - 19s 132us/sample - loss: 0.2605 - accuracy: 0.9016 - val_loss: 0.2498 - val_accuracy: 0.9065\n",
      "Epoch 4/5\n",
      "143998/143998 [==============================] - 19s 132us/sample - loss: 0.2571 - accuracy: 0.9031 - val_loss: 0.2928 - val_accuracy: 0.8822\n",
      "Epoch 5/5\n",
      "143998/143998 [==============================] - 19s 132us/sample - loss: 0.2510 - accuracy: 0.9064 - val_loss: 0.2451 - val_accuracy: 0.9111\n",
      "Running for: VGG19\n",
      "Train on 143998 samples, validate on 16000 samples\n",
      "Epoch 1/5\n",
      "143998/143998 [==============================] - 19s 131us/sample - loss: 0.3720 - accuracy: 0.8419 - val_loss: 0.3312 - val_accuracy: 0.8731\n",
      "Epoch 2/5\n",
      "143998/143998 [==============================] - 19s 130us/sample - loss: 0.3293 - accuracy: 0.8673 - val_loss: 0.3494 - val_accuracy: 0.8496\n",
      "Epoch 3/5\n",
      "143998/143998 [==============================] - 19s 131us/sample - loss: 0.3173 - accuracy: 0.8735 - val_loss: 0.2916 - val_accuracy: 0.8888\n",
      "Epoch 4/5\n",
      "143998/143998 [==============================] - 19s 131us/sample - loss: 0.3065 - accuracy: 0.8794 - val_loss: 0.2997 - val_accuracy: 0.8801\n",
      "Epoch 5/5\n",
      "143998/143998 [==============================] - 19s 130us/sample - loss: 0.3003 - accuracy: 0.8826 - val_loss: 0.2812 - val_accuracy: 0.8981\n",
      "Running for: Xception\n",
      "Train on 143998 samples, validate on 16000 samples\n",
      "Epoch 1/5\n",
      "143998/143998 [==============================] - 40s 278us/sample - loss: 0.3808 - accuracy: 0.8331 - val_loss: 0.2935 - val_accuracy: 0.8883\n",
      "Epoch 2/5\n",
      "143998/143998 [==============================] - 40s 278us/sample - loss: 0.2910 - accuracy: 0.8861 - val_loss: 0.3549 - val_accuracy: 0.8280\n",
      "Epoch 3/5\n",
      "143998/143998 [==============================] - 40s 278us/sample - loss: 0.2569 - accuracy: 0.9039 - val_loss: 0.2687 - val_accuracy: 0.8982\n",
      "Epoch 4/5\n",
      "143998/143998 [==============================] - 40s 277us/sample - loss: 0.2410 - accuracy: 0.9112 - val_loss: 0.2303 - val_accuracy: 0.9186\n",
      "Epoch 5/5\n",
      "143998/143998 [==============================] - 40s 277us/sample - loss: 0.2286 - accuracy: 0.9169 - val_loss: 0.2369 - val_accuracy: 0.9159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set up and train a network for each of the pretrained features available \n",
    "# and output histograms of correct vs incorrect classifications\n",
    "for net, depth in pretrained_models.items():\n",
    "    print(\"Running for:\", net)\n",
    "    \n",
    "    # Load features\n",
    "    if depth is None:\n",
    "        depth = \"full\"\n",
    "    features_filename = net + \"_d\" + str(depth) + \"_\" + str(images.shape[0]) + \".npy\"\n",
    "    pretrained_features = load_feature_representation(features_filename)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=pretrained_features.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Remove nan values from pretrained_features (and remove labels which produces them)\n",
    "    nan_indices = []\n",
    "    for i in range(pretrained_features.shape[0]):\n",
    "        if np.isnan(pretrained_features[i,:]).any():\n",
    "            nan_indices.append(i)\n",
    "    pretrained_features = np.delete(pretrained_features, nan_indices, axis=0)\n",
    "    tmp_labels = np.delete(labels, nan_indices, axis=0)\n",
    "    tmp_positions = np.delete(positions, nan_indices, axis=0)\n",
    "    tmp_energies = np.delete(energies, nan_indices, axis=0)\n",
    "\n",
    "    labels_positions_energies = np.concatenate((tmp_labels, tmp_positions, tmp_energies), axis=1)\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(pretrained_features, labels_positions_energies, test_size = 0.2)    \n",
    "\n",
    "    test_positions = y_test[:, 2:6]\n",
    "    train_positions = y_train[:, 2:6]\n",
    "    test_energies = y_test[:, 6:]\n",
    "    train_energies = y_train[:, 6:]\n",
    "    y_test = y_test[:, :2]\n",
    "    y_train = y_train[:, :2] \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x_train, \n",
    "        y_train, \n",
    "        epochs=5, \n",
    "        batch_size=32,\n",
    "        validation_split=0.1)\n",
    "    \n",
    "    tmp_predicted = model.predict(x_test)\n",
    "    tmp_results = tmp_predicted.argmax(axis=-1).reshape(tmp_predicted.shape[0], 1)\n",
    "\n",
    "    # indices, relative distances and relative energies for test set\n",
    "    single_indices, double_indices, close_indices = event_indices(test_positions)\n",
    "    rel_distance = relative_distance(test_positions)\n",
    "    rel_energy = relative_energy(test_energies)\n",
    "    \n",
    "    # double_events contain (predicted_class, distance between event origins)\n",
    "    # All the events are double events, so if predicted class is 0, the predicted\n",
    "    # class is wrong.\n",
    "\n",
    "    correct_doubles = np.where(tmp_results[double_indices] == 1)[0]\n",
    "    wrong_doubles = np.where(tmp_results[double_indices] == 0)[0]\n",
    "\n",
    "    mean_correct = np.mean(rel_distance[double_indices][correct_doubles])\n",
    "    mean_wrong = np.mean(rel_distance[double_indices][wrong_doubles])\n",
    "    mean_all = np.mean(rel_distance[double_indices])\n",
    "\n",
    "    ratio_doubles = len(correct_doubles) / len(double_indices)\n",
    "\n",
    "    # Ratio of correctly classified double events with a distance between\n",
    "    # events < 3mm\n",
    "    n_close = len(close_indices)\n",
    "    n_close_correct = len(np.where(rel_distance[double_indices][correct_doubles] < 3.0)[0])\n",
    "    ratio_close = n_close_correct / n_close\n",
    "\n",
    "    del(tmp_predicted)\n",
    "    del(tmp_results)\n",
    "    # Output\n",
    "\n",
    "    # Histograms\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(12,8))\n",
    "    ax[0,0].hist(rel_distance[double_indices][correct_doubles], bins=50, alpha=0.5, label=\"correct\")\n",
    "    ax[0,0].hist(rel_distance[double_indices][wrong_doubles], bins=50, alpha=0.5, label=\"wrong\")\n",
    "    ax[0,0].set_title(\"Relative distance\")\n",
    "    ax[0,0].legend()\n",
    "    ax[0,1].hist(rel_energy[double_indices][correct_doubles], bins=50, alpha=0.5, label=\"correct\")\n",
    "    ax[0,1].hist(rel_energy[double_indices][wrong_doubles], bins=50, alpha=0.5, label=\"wrong\")\n",
    "    ax[0,1].set_title(\"Relative energy\")\n",
    "    ax[0,1].legend()\n",
    "    ax[1,0].hist(rel_distance[double_indices], bins=50)\n",
    "    ax[1,0].set_title(\"Distribution of relative distances\")\n",
    "    ax[1,1].hist(rel_energy[double_indices], bins=50)\n",
    "    ax[1,1].set_title(\"Distribution of relative energies\")\n",
    "    #ax[1].text(0, 600, r'  $\\mu$ correct = {:.2f} mm'.format(mean_correct))\n",
    "    #ax[1].text(0, 550, r'  $\\mu$ wrong = {:.2f} mm'.format(mean_wrong))\n",
    "    #ax[1].text(0, 500, r'  ratio doubles < 3mm = {:.2f}'.format(ratio_doubles))\n",
    "    #ax[1].text(0, 650, r'  $\\mu$ all = {:.2f} mm'.format(mean_all))\n",
    "    #ax[1].set_title(\"Numbers\")\n",
    "    figure_name = net + \"_d\" + str(depth) + \"_\" + str(images.shape[0]) + \"_relative.png\"\n",
    "    fig.savefig(figure_name, format=\"png\")\n",
    "    fig.clf()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pretrained_venv",
   "language": "python",
   "name": "pretrained_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
