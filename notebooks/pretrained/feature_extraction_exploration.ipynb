{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from master_data_functions.functions import import_data,save_feature_representation,load_feature_representation, event_indices\n",
    "from master_models.pretrained import pretrained_model\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 2\n",
      "Input Images shape: (200000, 16, 16, 1)\n",
      "Energies shape: (200000, 2)\n",
      "Positions shape: (200000, 4)\n",
      "Labels shape: (200000, 2)\n",
      "Reshaped Images data shape: (200000, 16, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "\n",
    "# File import\n",
    "# Sample filenames are:\n",
    "# CeBr10kSingle_1.txt -> single events, \n",
    "# CeBr10kSingle_2.txt -> single events\n",
    "# CeBr10k_1.txt -> mixed single and double events \n",
    "# CeBr10.txt -> small file of 10 samples\n",
    "# CeBr2Mil_Mix.txt -> 2 million mixed samples of simulated events\n",
    "\n",
    "# Flag import, since we can now import 200k events from .npy files\n",
    "from_file = False\n",
    "if from_file:\n",
    "\n",
    "    folder = \"simulated\"\n",
    "    filename = \"CeBr2Mil_Mix.txt\"\n",
    "    num_samples = 2e5\n",
    "    #folder = \"sample\"\n",
    "    #filename = \"CeBr10k_1.txt\"\n",
    "    #num_samples = 1e3\n",
    "\n",
    "    data = import_data(folder=folder, filename=filename, num_samples=num_samples)\n",
    "    images = data[filename][\"images\"]\n",
    "    energies = data[filename][\"energies\"]\n",
    "    positions = data[filename][\"positions\"]\n",
    "    labels = to_categorical(data[filename][\"labels\"])\n",
    "    n_classes = labels.shape[1]\n",
    "else:\n",
    "    images = load_feature_representation(\"images_200k.npy\")\n",
    "    energies = load_feature_representation(\"energies_200k.npy\")\n",
    "    positions = load_feature_representation(\"positions_200k.npy\")\n",
    "    labels = load_feature_representation(\"labels_200k.npy\")\n",
    "\n",
    "n_classes = labels.shape[1]\n",
    "print(\"Number of classes: {}\".format(n_classes))\n",
    "print(\"Input Images shape: {}\".format(images.shape))\n",
    "print(\"Energies shape: {}\".format(energies.shape))\n",
    "print(\"Positions shape: {}\".format(positions.shape))\n",
    "print(\"Labels shape: {}\".format(labels.shape))\n",
    "\n",
    "# VGG16 expects 3 channels. Solving this by concatenating the image data \n",
    "# to itself, to form three identical channels\n",
    "\n",
    "images = np.concatenate((images, images, images), axis=3)\n",
    "print(\"Reshaped Images data shape: {}\".format(images.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save feature representations for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keys: model names, Values: depth to compare at.\n",
    "pretrained_models = {\n",
    "    \"DenseNet121\":None, #8\n",
    "    \"DenseNet169\":None, #8\n",
    "    \"DenseNet201\":None, #8\n",
    "    \"InceptionResNetV2\":None, #8\n",
    "    \"InceptionV3\":None, #8\n",
    "    \"MobileNet\":None, #8\n",
    "    \"MobileNetV2\":None, #5\n",
    "    \"NASNetLarge\":None, #4\n",
    "    \"NASNetMobile\":None, #4\n",
    "    \"ResNet50\":None, #8\n",
    "    \"VGG16\":None,\n",
    "    \"VGG19\":None,\n",
    "    \"Xception\":None, #6\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save feature representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for net, depth in pretrained_models.items():\n",
    "    print(\"Running for:\", net)\n",
    "    # Build net at desired depth\n",
    "    pretrained = pretrained_model(which_model=net, output_depth=depth)\n",
    "    \n",
    "    # Extract features and split them into single and double\n",
    "    pretrained_features = pretrained.predict(images)\n",
    "    \n",
    "    if depth is None:\n",
    "        depth = \"full\"\n",
    "    features_filename = net + \"_d\" + str(depth) + \"_\" + str(pretrained_features.shape[0]) + \"npy\"\n",
    "    save_feature_representation(pretrained_features, features_filename)\n",
    "    \n",
    "    # Delete to free memory for next iteration just in case\n",
    "    del pretrained_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test feature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Kolmogorov-Smirnov test\n",
    "from scipy.stats import ks_2samp\n",
    "from joblib import Parallel, delayed\n",
    "# Check difference using Kolmogorov-Smirnov\n",
    "\n",
    "def get_pval(i):\n",
    "    ks = ks_2samp(single_features[:,i], double_features[:,i])\n",
    "    return ks.pvalue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolmogorov-Smirnov 2-sample test for all networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: DenseNet121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 247 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 497 out of 512 | elapsed:    5.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 512 out of 512 | elapsed:    5.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: DenseNet169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 429 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 497 out of 512 | elapsed:    3.9s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 512 out of 512 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: DenseNet201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 251 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 497 out of 512 | elapsed:    4.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 512 out of 512 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: InceptionResNetV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: InceptionV3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: MobileNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1969 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2048 out of 2048 | elapsed:   53.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: MobileNetV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 369 out of 384 | elapsed:    2.8s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 384 out of 384 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: NASNetLarge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1969 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2058 out of 2058 | elapsed:   40.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: NASNetMobile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 432 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 524 out of 539 | elapsed:    3.7s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 539 out of 539 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: ResNet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed:   52.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1969 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3265 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4096 out of 4096 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: VGG16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 247 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 497 out of 512 | elapsed:    4.5s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 512 out of 512 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: VGG19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 435 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 512 out of 512 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: Xception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed:   49.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1969 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3200 out of 3200 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "# Run test on all pretrained nets.\n",
    "p_output = {}\n",
    "\n",
    "\n",
    "for net, depth in pretrained_models.items():\n",
    "    print(\"Running for:\", net)\n",
    "    \n",
    "    # Load features\n",
    "    if depth is None:\n",
    "        depth = \"full\"\n",
    "    features_filename = net + \"_d\" + str(depth) + \"_\" + str(labels.shape[0]) + \".npy\"\n",
    "    pretrained_features = load_feature_representation(features_filename)\n",
    "    single_features = pretrained_features[np.where(labels[:,0] == 1)]\n",
    "    double_features = pretrained_features[np.where(labels[:,1] == 1)]\n",
    "    n = pretrained_features.shape[1]\n",
    "    p_values = Parallel(n_jobs=-1, verbose=2)(delayed(get_pval)(i) for i in range(n))\n",
    "    p_output[net] = p_values\n",
    "    \n",
    "    #plt.close()\n",
    "    #plt.plot(range(len(p_values)), p_values, label=net)\n",
    "    #plt.legend()\n",
    "    #plt.savefig(net + \"-p-vals.png\")\n",
    "    \n",
    "    # Delete allocated arrays for saving memory in notebook\n",
    "    del pretrained_features\n",
    "    del single_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output table of KS 2-sample test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of p-values below thresholds for each net to check\n",
    "# if it's reasonable to reject the null-hypothesis (no difference in distributions)\n",
    "ks_statistics = []\n",
    "for key, val in p_output.items():\n",
    "    pvals = np.array(p_output[key])\n",
    "    n_features = len(pvals)\n",
    "    n_below_1 = len(np.where(pvals < 0.01)[0])\n",
    "    n_below_05 = len(np.where(pvals < 0.005)[0])\n",
    "    n_below_01 = len(np.where(pvals < 0.001)[0])\n",
    "    ks_statistics.append(\n",
    "        [key, \n",
    "         n_features, \n",
    "         n_below_1/n_features,\n",
    "         n_below_05/n_features,\n",
    "         n_below_01/n_features,\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\hline\n",
      " Network           &   num\\_features &   ratio p \\ensuremath{<} 0.01 &   ratio p \\ensuremath{<} 0.005 &   ratio p \\ensuremath{<} 0.001 \\\\\n",
      "\\hline\n",
      " DenseNet121       &            512 &         1        &          1        &          1        \\\\\n",
      " DenseNet169       &            512 &         1        &          1        &          1        \\\\\n",
      " DenseNet201       &            512 &         1        &          1        &          1        \\\\\n",
      " InceptionResNetV2 &            320 &         0.96875  &          0.96875  &          0.965625 \\\\\n",
      " InceptionV3       &            320 &         0.98125  &          0.98125  &          0.98125  \\\\\n",
      " MobileNet         &           2048 &         0.227051 &          0.227051 &          0.227051 \\\\\n",
      " MobileNetV2       &            384 &         1        &          1        &          1        \\\\\n",
      " NASNetLarge       &           2058 &         0.510204 &          0.510204 &          0.510204 \\\\\n",
      " NASNetMobile      &            539 &         0.510204 &          0.510204 &          0.510204 \\\\\n",
      " ResNet50          &           4096 &         1        &          1        &          1        \\\\\n",
      " VGG16             &            512 &         0.632812 &          0.632812 &          0.626953 \\\\\n",
      " VGG19             &            512 &         0.652344 &          0.652344 &          0.652344 \\\\\n",
      " Xception          &           3200 &         1        &          1        &          1        \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "# Output as latex table\n",
    "headers = [\"Network\", \"num_features\", \"ratio p < 0.01\", \"ratio p < 0.005\", \"ratio p < 0.001\"]\n",
    "print(tabulate(ks_statistics, headers, tablefmt=\"latex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare single events and close double events\n",
    "'Close' double events are events separated by a distance less than 3 mm.\n",
    "This length is chose because that is the width of one pixel in the image data, and\n",
    "it is below this distance that the models seem to struggle the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: DenseNet121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 512 out of 512 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: DenseNet169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 512 out of 512 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: DenseNet201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 512 out of 512 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: InceptionResNetV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: InceptionV3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: MobileNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 423 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1235 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2048 out of 2048 | elapsed:   10.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: MobileNetV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 384 out of 384 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: NASNetLarge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 423 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1235 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2043 out of 2058 | elapsed:   10.5s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2058 out of 2058 | elapsed:   10.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: NASNetMobile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 539 out of 539 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: ResNet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1969 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=-1)]: Done 3265 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4096 out of 4096 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: VGG16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 512 out of 512 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: VGG19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 512 out of 512 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: Xception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1969 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed:   47.9s\n",
      "[Parallel(n_jobs=-1)]: Done 3200 out of 3200 | elapsed:   59.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Run test on all pretrained nets.\n",
    "p_output = {}\n",
    "\n",
    "\n",
    "for net, depth in pretrained_models.items():\n",
    "    print(\"Running for:\", net)\n",
    "    \n",
    "    # Load features\n",
    "    if depth is None:\n",
    "        depth = \"full\"\n",
    "    features_filename = net + \"_d\" + str(depth) + \"_\" + str(images.shape[0]) + \".npy\"\n",
    "    pretrained_features = load_feature_representation(features_filename)\n",
    "    single_features = pretrained_features[np.where(labels[:,0] == 1)]\n",
    "    single_indices, double_indices, close_indices = event_indices(positions)\n",
    "    double_features = pretrained_features[close_indices]\n",
    "    n = pretrained_features.shape[1]\n",
    "    p_values = Parallel(n_jobs=-1, verbose=2)(delayed(get_pval)(i) for i in range(n))\n",
    "    p_output[net] = p_values\n",
    "    \n",
    "    #plt.close()\n",
    "    #plt.plot(range(len(p_values)), p_values, label=net)\n",
    "    #plt.legend()\n",
    "    #plt.savefig(net + \"_close\" + \"-p-vals.png\")\n",
    "    \n",
    "    # Delete allocated arrays for saving memory in notebook\n",
    "    del pretrained_features\n",
    "    del single_features\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of p-values below thresholds for each net to check\n",
    "# if it's reasonable to reject the null-hypothesis (no difference in distributions)\n",
    "ks_statistics = []\n",
    "for key, val in p_output.items():\n",
    "    pvals = np.array(p_output[key])\n",
    "    n_features = len(pvals)\n",
    "    n_below_1 = len(np.where(pvals < 0.01)[0])\n",
    "    n_below_05 = len(np.where(pvals < 0.005)[0])\n",
    "    n_below_01 = len(np.where(pvals < 0.001)[0])\n",
    "    ks_statistics.append(\n",
    "        [key, \n",
    "         n_features, \n",
    "         n_below_1/n_features,\n",
    "         n_below_05/n_features,\n",
    "         n_below_01/n_features,\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11006\n",
      "\\begin{tabular}{lrrrr}\n",
      "\\hline\n",
      " Network           &   num\\_features &   ratio p \\ensuremath{<} 0.01 &   ratio p \\ensuremath{<} 0.005 &   ratio p \\ensuremath{<} 0.001 \\\\\n",
      "\\hline\n",
      " DenseNet121       &            512 &         1        &          1        &          1        \\\\\n",
      " DenseNet169       &            512 &         0.998047 &          0.998047 &          0.998047 \\\\\n",
      " DenseNet201       &            512 &         1        &          1        &          1        \\\\\n",
      " InceptionResNetV2 &            320 &         0.96875  &          0.96875  &          0.965625 \\\\\n",
      " InceptionV3       &            320 &         0.971875 &          0.96875  &          0.9625   \\\\\n",
      " MobileNet         &           2048 &         0.22168  &          0.221191 &          0.21875  \\\\\n",
      " MobileNetV2       &            384 &         1        &          1        &          1        \\\\\n",
      " NASNetLarge       &           2058 &         0.480564 &          0.474247 &          0.456754 \\\\\n",
      " NASNetMobile      &            539 &         0.458256 &          0.445269 &          0.419295 \\\\\n",
      " ResNet50          &           4096 &         1        &          0.999756 &          0.999512 \\\\\n",
      " VGG16             &            512 &         0.601562 &          0.599609 &          0.597656 \\\\\n",
      " VGG19             &            512 &         0.642578 &          0.642578 &          0.638672 \\\\\n",
      " Xception          &           3200 &         1        &          1        &          0.999062 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# Output as latex table\n",
    "print(len(close_indices))\n",
    "headers = [\"Network\", \"num_features\", \"ratio p < 0.01\", \"ratio p < 0.005\", \"ratio p < 0.001\"]\n",
    "print(tabulate(ks_statistics, headers, tablefmt=\"latex\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n",
      "11006\n"
     ]
    }
   ],
   "source": [
    "print(len(single_indices))\n",
    "print(len(double_indices))\n",
    "print(len(close_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Plot features for some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_inspect = False\n",
    "if manual_inspect:\n",
    "    # Compare feature output for reference image with a single and double image\n",
    "    plt.plot(range(len(reference_features[0])), reference_features[0], alpha=0.5, label='reference')\n",
    "    plt.plot(range(len(single_features[0])), single_features[0], alpha=0.5, label='single')\n",
    "    plt.plot(range(len(double_features[0])), double_features[0], alpha=0.5, label='double')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Check distribution of features by inspection\n",
    "    index = 0 \n",
    "    fig, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(12,12))\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            # plot features\n",
    "            ax[i, j].hist(single_features[:,index + i*3 + j], alpha=0.5, label='single')\n",
    "            ax[i, j].hist(double_features[:,index + i*3 + j], alpha=0.5, label='double')\n",
    "            ax[i, j].hist(ref_vgg_features, alpha=0.5, label='reference')\n",
    "            ax[i, j].legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pretrained_venv",
   "language": "python",
   "name": "pretrained_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
