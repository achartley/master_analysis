{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from master_data_functions.functions import import_data,save_feature_representation,load_feature_representation, event_indices\n",
    "from master_models.pretrained import pretrained_model\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 2\n",
      "Input Images shape: (199998, 16, 16, 3)\n",
      "Energies shape: (199998, 2)\n",
      "Positions shape: (199998, 4)\n",
      "Labels shape: (199998, 2)\n",
      "Reshaped Images data shape: (199998, 16, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "\n",
    "# File import\n",
    "# Sample filenames are:\n",
    "# CeBr10kSingle_1.txt -> single events, \n",
    "# CeBr10kSingle_2.txt -> single events\n",
    "# CeBr10k_1.txt -> mixed single and double events \n",
    "# CeBr10.txt -> small file of 10 samples\n",
    "# CeBr2Mil_Mix.txt -> 2 million mixed samples of simulated events\n",
    "\n",
    "# Flag import, since we can now import 200k events from .npy files\n",
    "from_file = False\n",
    "if from_file:\n",
    "\n",
    "    folder = \"simulated\"\n",
    "    filename = \"CeBr2Mil_Mix.txt\"\n",
    "    num_samples = 2e5\n",
    "    #folder = \"sample\"\n",
    "    #filename = \"CeBr10k_1.txt\"\n",
    "    #num_samples = 1e3\n",
    "\n",
    "    data = import_data(folder=folder, filename=filename, num_samples=num_samples)\n",
    "    images = data[filename][\"images\"]\n",
    "    energies = data[filename][\"energies\"]\n",
    "    positions = data[filename][\"positions\"]\n",
    "    labels = to_categorical(data[filename][\"labels\"])\n",
    "    n_classes = labels.shape[1]\n",
    "else:\n",
    "    images = load_feature_representation(\"images_200k.npy\")\n",
    "    energies = load_feature_representation(\"energies_200k.npy\")\n",
    "    positions = load_feature_representation(\"positions_200k.npy\")\n",
    "    labels = load_feature_representation(\"labels_200k.npy\")\n",
    "\n",
    "n_classes = labels.shape[1]\n",
    "print(\"Number of classes: {}\".format(n_classes))\n",
    "print(\"Input Images shape: {}\".format(images.shape))\n",
    "print(\"Energies shape: {}\".format(energies.shape))\n",
    "print(\"Positions shape: {}\".format(positions.shape))\n",
    "print(\"Labels shape: {}\".format(labels.shape))\n",
    "\n",
    "# VGG16 expects 3 channels. Solving this by concatenating the image data \n",
    "# to itself, to form three identical channels\n",
    "\n",
    "#images = np.concatenate((images, images, images), axis=3)\n",
    "print(\"Reshaped Images data shape: {}\".format(images.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save feature representations for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keys: model names, Values: depth to compare at.\n",
    "pretrained_models = {\n",
    "    #\"DenseNet121\":None, #8\n",
    "    #\"DenseNet169\":None, #8\n",
    "    #\"DenseNet201\":None, #8\n",
    "    #\"InceptionResNetV2\":None, #8\n",
    "    #\"InceptionV3\":None, #8\n",
    "    #\"MobileNet\":None, #8\n",
    "    #\"MobileNetV2\":None, #5\n",
    "    #\"NASNetLarge\":None, #4\n",
    "    #\"NASNetMobile\":None, #4\n",
    "    \"ResNet50\":None, #8\n",
    "    \"VGG16\":None,\n",
    "    \"VGG19\":None,\n",
    "    \"Xception\":None, #6\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save feature representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: ResNet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geir/git/master_analysis/notebooks/pretrained/pretrained_venv/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: VGG16\n",
      "Running for: VGG19\n",
      "Running for: Xception\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for net, depth in pretrained_models.items():\n",
    "    print(\"Running for:\", net)\n",
    "    # Build net at desired depth\n",
    "    pretrained = pretrained_model(which_model=net, output_depth=depth)\n",
    "    \n",
    "    # Extract features and split them into single and double\n",
    "    pretrained_features = pretrained.predict(images)\n",
    "    \n",
    "    if depth is None:\n",
    "        depth = \"full\"\n",
    "    features_filename = net + \"_d\" + str(depth) + \"_\" + str(pretrained_features.shape[0]) + \"npy\"\n",
    "    save_feature_representation(pretrained_features, features_filename)\n",
    "    \n",
    "    # Delete to free memory for next iteration just in case\n",
    "    del pretrained_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test feature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Kolmogorov-Smirnov test\n",
    "from scipy.stats import ks_2samp\n",
    "from joblib import Parallel, delayed\n",
    "# Check difference using Kolmogorov-Smirnov\n",
    "\n",
    "def get_pval(i):\n",
    "    ks = ks_2samp(single_features[:,i], double_features[:,i])\n",
    "    return ks.pvalue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolmogorov-Smirnov 2-sample test for all networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test on all pretrained nets.\n",
    "p_output = {}\n",
    "\n",
    "\n",
    "for net, depth in pretrained_models.items():\n",
    "    print(\"Running for:\", net)\n",
    "    \n",
    "    # Load features\n",
    "    if depth is None:\n",
    "        depth = \"full\"\n",
    "    features_filename = net + \"_d\" + str(depth) + \"_\" + str(labels.shape[0]) + \".npy\"\n",
    "    pretrained_features = load_feature_representation(features_filename)\n",
    "    single_features = pretrained_features[np.where(labels[:,0] == 1)]\n",
    "    double_features = pretrained_features[np.where(labels[:,1] == 1)]\n",
    "    n = pretrained_features.shape[1]\n",
    "    p_values = Parallel(n_jobs=-1, verbose=2)(delayed(get_pval)(i) for i in range(n))\n",
    "    p_output[net] = p_values\n",
    "    \n",
    "    #plt.close()\n",
    "    #plt.plot(range(len(p_values)), p_values, label=net)\n",
    "    #plt.legend()\n",
    "    #plt.savefig(net + \"-p-vals.png\")\n",
    "    \n",
    "    # Delete allocated arrays for saving memory in notebook\n",
    "    del pretrained_features\n",
    "    del single_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output table of KS 2-sample test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of p-values below thresholds for each net to check\n",
    "# if it's reasonable to reject the null-hypothesis (no difference in distributions)\n",
    "ks_statistics = []\n",
    "for key, val in p_output.items():\n",
    "    pvals = np.array(p_output[key])\n",
    "    n_features = len(pvals)\n",
    "    n_below_1 = len(np.where(pvals < 0.01)[0])\n",
    "    n_below_05 = len(np.where(pvals < 0.005)[0])\n",
    "    n_below_01 = len(np.where(pvals < 0.001)[0])\n",
    "    ks_statistics.append(\n",
    "        [key, \n",
    "         n_features, \n",
    "         n_below_1/n_features,\n",
    "         n_below_05/n_features,\n",
    "         n_below_01/n_features,\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "# Output as latex table\n",
    "headers = [\"Network\", \"num_features\", \"ratio p < 0.01\", \"ratio p < 0.005\", \"ratio p < 0.001\"]\n",
    "print(tabulate(ks_statistics, headers, tablefmt=\"latex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare single events and close double events\n",
    "'Close' double events are events separated by a distance less than 3 mm.\n",
    "This length is chose because that is the width of one pixel in the image data, and\n",
    "it is below this distance that the models seem to struggle the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run test on all pretrained nets.\n",
    "p_output = {}\n",
    "\n",
    "\n",
    "for net, depth in pretrained_models.items():\n",
    "    print(\"Running for:\", net)\n",
    "    \n",
    "    # Load features\n",
    "    if depth is None:\n",
    "        depth = \"full\"\n",
    "    features_filename = net + \"_d\" + str(depth) + \"_\" + str(images.shape[0]) + \".npy\"\n",
    "    pretrained_features = load_feature_representation(features_filename)\n",
    "    single_features = pretrained_features[np.where(labels[:,0] == 1)]\n",
    "    single_indices, double_indices, close_indices = event_indices(positions)\n",
    "    double_features = pretrained_features[close_indices]\n",
    "    n = pretrained_features.shape[1]\n",
    "    p_values = Parallel(n_jobs=-1, verbose=2)(delayed(get_pval)(i) for i in range(n))\n",
    "    p_output[net] = p_values\n",
    "    \n",
    "    #plt.close()\n",
    "    #plt.plot(range(len(p_values)), p_values, label=net)\n",
    "    #plt.legend()\n",
    "    #plt.savefig(net + \"_close\" + \"-p-vals.png\")\n",
    "    \n",
    "    # Delete allocated arrays for saving memory in notebook\n",
    "    del pretrained_features\n",
    "    del single_features\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of p-values below thresholds for each net to check\n",
    "# if it's reasonable to reject the null-hypothesis (no difference in distributions)\n",
    "ks_statistics = []\n",
    "for key, val in p_output.items():\n",
    "    pvals = np.array(p_output[key])\n",
    "    n_features = len(pvals)\n",
    "    n_below_1 = len(np.where(pvals < 0.01)[0])\n",
    "    n_below_05 = len(np.where(pvals < 0.005)[0])\n",
    "    n_below_01 = len(np.where(pvals < 0.001)[0])\n",
    "    ks_statistics.append(\n",
    "        [key, \n",
    "         n_features, \n",
    "         n_below_1/n_features,\n",
    "         n_below_05/n_features,\n",
    "         n_below_01/n_features,\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Output as latex table\n",
    "print(len(close_indices))\n",
    "headers = [\"Network\", \"num_features\", \"ratio p < 0.01\", \"ratio p < 0.005\", \"ratio p < 0.001\"]\n",
    "print(tabulate(ks_statistics, headers, tablefmt=\"latex\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(single_indices))\n",
    "print(len(double_indices))\n",
    "print(len(close_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Plot features for some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_inspect = False\n",
    "if manual_inspect:\n",
    "    # Compare feature output for reference image with a single and double image\n",
    "    plt.plot(range(len(reference_features[0])), reference_features[0], alpha=0.5, label='reference')\n",
    "    plt.plot(range(len(single_features[0])), single_features[0], alpha=0.5, label='single')\n",
    "    plt.plot(range(len(double_features[0])), double_features[0], alpha=0.5, label='double')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Check distribution of features by inspection\n",
    "    index = 0 \n",
    "    fig, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(12,12))\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            # plot features\n",
    "            ax[i, j].hist(single_features[:,index + i*3 + j], alpha=0.5, label='single')\n",
    "            ax[i, j].hist(double_features[:,index + i*3 + j], alpha=0.5, label='double')\n",
    "            ax[i, j].hist(ref_vgg_features, alpha=0.5, label='reference')\n",
    "            ax[i, j].legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pretrained_venv",
   "language": "python",
   "name": "pretrained_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
